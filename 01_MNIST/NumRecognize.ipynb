{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义只有含有一个隐藏层的神经网络，隐藏层结点数为200，使用relu作为激活函数。损失函数为信息交叉熵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "Iter 1 Test accury is 0.95560 with learning rate 0.001000\n",
      "Iter 2 Test accury is 0.96570 with learning rate 0.000950\n",
      "Iter 3 Test accury is 0.97280 with learning rate 0.000903\n",
      "Iter 4 Test accury is 0.97600 with learning rate 0.000857\n",
      "Iter 5 Test accury is 0.97650 with learning rate 0.000815\n",
      "Iter 6 Test accury is 0.97680 with learning rate 0.000774\n",
      "Iter 7 Test accury is 0.97890 with learning rate 0.000735\n",
      "Iter 8 Test accury is 0.97660 with learning rate 0.000698\n",
      "Iter 9 Test accury is 0.98020 with learning rate 0.000663\n",
      "Iter 10 Test accury is 0.97830 with learning rate 0.000630\n",
      "Iter 11 Test accury is 0.97820 with learning rate 0.000599\n",
      "Iter 12 Test accury is 0.98020 with learning rate 0.000569\n",
      "Iter 13 Test accury is 0.97880 with learning rate 0.000540\n",
      "Iter 14 Test accury is 0.97980 with learning rate 0.000513\n",
      "Iter 15 Test accury is 0.98260 with learning rate 0.000488\n",
      "Iter 16 Test accury is 0.98100 with learning rate 0.000463\n",
      "Iter 17 Test accury is 0.98100 with learning rate 0.000440\n",
      "Iter 18 Test accury is 0.98090 with learning rate 0.000418\n",
      "Iter 19 Test accury is 0.97940 with learning rate 0.000397\n",
      "Iter 20 Test accury is 0.98000 with learning rate 0.000377\n",
      "Iter 21 Test accury is 0.98100 with learning rate 0.000358\n",
      "Iter 22 Test accury is 0.98110 with learning rate 0.000341\n",
      "Iter 23 Test accury is 0.98080 with learning rate 0.000324\n",
      "Iter 24 Test accury is 0.98160 with learning rate 0.000307\n",
      "Iter 25 Test accury is 0.98180 with learning rate 0.000292\n",
      "Iter 26 Test accury is 0.98100 with learning rate 0.000277\n",
      "Iter 27 Test accury is 0.98140 with learning rate 0.000264\n",
      "Iter 28 Test accury is 0.98190 with learning rate 0.000250\n",
      "Iter 29 Test accury is 0.98150 with learning rate 0.000238\n",
      "Iter 30 Test accury is 0.98180 with learning rate 0.000226\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 设置数据存储路径\n",
    "data_path = 'data/'\n",
    "mnist = input_data.read_data_sets(data_path, one_hot=True)\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "dim1 = 200\n",
    "\n",
    "w1 = tf.Variable(tf.truncated_normal((784, dim1), stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros((1, dim1)))\n",
    "\n",
    "dim2 = 100\n",
    "w2 = tf.Variable(tf.truncated_normal((dim1, dim2), stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros((1, dim2)))\n",
    "\n",
    "dim3 = 10\n",
    "w3 = tf.Variable(tf.truncated_normal((dim2, dim3), stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros((1, dim3)))\n",
    "\n",
    "layer1 = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
    "layer2 = tf.nn.relu(tf.matmul(layer1, w2) + b2)\n",
    "y_ = tf.matmul(layer2, w3) + b3\n",
    "\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_)\n",
    "loss = tf.reduce_mean(loss)\n",
    "\n",
    "lr = tf.Variable(0., dtype=tf.float32)\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "batch_size = 100\n",
    "batch_num = mnist.train.num_examples // batch_size\n",
    "\n",
    "# 计算机准确率\n",
    "# 学习到的函数 tf.argmax() 返回最大值的下标\n",
    "accury = tf.equal(tf.argmax(y_, axis=1), tf.argmax(y, axis=1))\n",
    "accury = tf.reduce_mean(tf.cast(accury, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(30):\n",
    "        sess.run(tf.assign(lr, 0.001 *(0.95**epoch)))\n",
    "        for _ in range(batch_num):\n",
    "            xs, ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step, feed_dict={x:xs, y:ys})\n",
    "        \n",
    "        temp_accury = sess.run(accury, feed_dict={x:mnist.test.images, y:mnist.test.labels})\n",
    "        \n",
    "        print('Iter %d Test accury is %.5f with learning rate %f' %(epoch+1, temp_accury, sess.run(lr)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0598311]\n"
     ]
    }
   ],
   "source": [
    "# 学习softmax_cross_entropy_with_logits函数\n",
    "y = tf.constant([[0.5, 0.2, 0.3]])\n",
    "y_ = tf.constant([[0.5, 0.2, 0.3]])\n",
    "result = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
